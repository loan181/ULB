\documentclass{article}

\usepackage[french]{babel}
\usepackage{commath}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{palatino}
\usepackage{eulervm}
\usepackage{fullpage}
\usepackage[parfill]{parskip}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{mathrsfs}

% amsthm
\newtheorem{thm}{Théorème}[section]
\newtheorem{prp}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollaire}
\newtheorem{lem}[thm]{Lemme}
\newtheorem{axiome}[thm]{Axiome}
\addto\captionsfrench{\renewcommand\proofname{\underline{Démonstration}}}
\theoremstyle{definition}
\newtheorem{déf}[thm]{Définition}
\theoremstyle{remark}
\newtheorem*{rmq}{Remarque}
\newtheorem{ex}{Exemple}[section]

\title{INFOF-302 --- Informatique fondamentale}
\author{R. Petit}
\date{Année académique 2016 - 2017}

\newcommand{\intint}[2]{\left\llbracket#1, #2\right\rrbracket}
\newcommand{\logeval}[1]{\left\llbracket#1\right\rrbracket}
\newcommand{\N}{\mathbb N}
\newcommand{\R}{\mathbb R}

\newcommand{\tq}{\text{ t.q. }}

\newcommand{\NP}{\mathcal {NP}}

\DeclareMathOperator{\ExpTime}{ExpTime}

\begin{document}
\pagenumbering{Roman}
\maketitle
\tableofcontents
\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

\section{Introduction et Logique}
	\begin{déf} \textit{Réduire} un problème de décision $A$ en un problème de décision $B$ correspond à trouver un algorithme permettant d'encoder toute
	entrée $I_A$ du problème $A$ en une entrée $I_B$ du problème $B$ telle que $I_A$ a une solution pour le problème $A$ si et seulement si $I_B$
	a une solution pour le problème $B$.
	\end{déf}

	\begin{déf} \textit{Réduire} un problème général $A$ en un problème $B$ correspond à trouver un algorithme d'encodage de toute entrée $I_A$ du problème
	$A$ en une entrée $I_B$ du problème $B$ et de décodage de toute sortie $O_B$ en une sortie $O_A$.
	\end{déf}

	\begin{axiome} Pour $\prec$, une relation d'ordre sur la priorité des opérateurs logiques. On prend~:
	\[\Leftrightarrow \quad\prec\quad \Rightarrow \quad\prec\quad \lor \quad\prec\quad \land \quad\prec\quad \lnot.\]
	\end{axiome}

	Afin d'étudier une formule logique, on peut construire son \textit{arbre de lecture} en séparant la formule aux opérateurs, par ordre
	croissant de priorité.

	\begin{déf} Pour $P$, un ensemble de propositions, on appelle \textit{fonction d'interprétation} (ou \textit{valuation}) toute fonction~:
	\[V : P \to \{0, 1\} : p \mapsto V(p).\]
	\end{déf}

	\begin{déf} Soit $\phi$ une formule bien formée sur un ensemble de propositions $P$. On définit sa \textit{valeur de vérité} évaluée en $V \in \{0, 1\}^P$
	par la fonction~:
	\[\logeval \phi_\cdot : \{0, 1\}^P \to \{0, 1\} : V \mapsto \logeval \phi_V,\]
	dont la	valeur est induite syntaxiquement.

	Pour $V$ une valuation, lorsque $\logeval \phi_V = 1$, on note $V \models \phi$, que l'on lit \textit{$V$ satisfait $\phi$}.
	\end{déf}

	\begin{déf} Soit $\phi$, une formule sur $P$.
	\begin{itemize}
		\item lorsque $\logeval \phi_\cdot^{-1}(\{1\}) \neq \emptyset$, on dit que $\phi$ est \textit{satisfaisable}~;
		\item lorsque $\logeval \phi_\cdot^{-1}(\{1\}) = \{0, 1\}^P$, on dit que $\phi$ est \textit{valide}.
	\end{itemize}
	\end{déf}

	\begin{lem} Soit $\phi$, une formule sur $P$. Si $\phi$ est valide, alors $\phi$ est satisfaisable.
	\end{lem}

	\begin{déf} Soient $n \in \N^*$, $\{\phi_i\}_{i \in \intint 1n}$ et $\phi$, des formules sur $P$. On dit que $\phi$ est une conséquence logique de
	$\{\phi_i\}_{i \in \intint 1n}$ lorsque la formule~:
	\[\bigwedge_{i=1}^n\phi_i \Rightarrow \phi\]
	est valide. On note cela $\phi_1, \ldots, \phi_n \models \phi$.
	\end{déf}

	\begin{déf} Deux formules $\phi$ et $\psi$ sur $P$ sont dites \textit{équivalentes} lorsque $\phi \Leftrightarrow \psi$ est valide. On note cela
	$\phi \equiv \psi$.
	\end{déf}

	\begin{thm} Une formule $\phi$ sur $P$ est valide si et seulement si sa négation est non-satisfaisable.
	\end{thm}

	\begin{proof} Soit $\phi$, une formule valide sur $P$. On sait alors que $\logeval \phi_\cdot^{-1}(\{1\}) = \{0, 1\}^P$. On en déduit que~:
	\[\logeval\phi_\cdot^{-1}(\{0\}) = \{0, 1\}^P \setminus \logeval \phi_\cdot^{-1}(\{1\}) = \emptyset.\]

	Or $\forall V \in \{0, 1\}^P : \logeval \phi_V = 1-\logeval {\lnot\phi}_V$. On en déduit que~:
	\[\logeval {\lnot \phi}_\cdot^{-1}(\{1\}) = \logeval {\phi}_\cdot^{-1}(\{0\}) = \emptyset.\]

	Idem pour $\Leftarrow$
	\end{proof}

	\begin{rmq} On en déduit qu'un algorithme qui détermine la satisfaisabilité d'une expression permet également de déterminer la validité.
	\end{rmq}

	\begin{déf} Un \textit{littéral} est soit une proposition $x \in P$, soit la négation $\lnot x$ d'une proposition.
	\end{déf}

	\begin{déf} Un ensemble $S$ de littéraux est dit \textit{satisfaisable} lorsqu'il ne contient pas une paire de littéraux complémentaires, i.e.~:
	\[\forall x \in S : \lnot x \not \in S.\]
	\end{déf}

	Pour déterminer la satisfaisabilité d'une formule, on peut créer son arbre sémantique par application des $\land$-règles et $\lor$-règles. Pour cela,
	on part de de la formule, et on applique le pas de simplification soit dur une conjonction, soit sur une disjonction (en ayant transformé tous les
	autres opérateurs en conjonctions/disjonctions au préalable).

	\begin{ex}
	\begin{align*}
		\phi \coloneqq &(x \lor y) \land (\lnot x \land \lnot y) \\
		&\left\{(x \lor y) \land (\lnot x \land \lnot y)\right\} \\
		&\left\{(x \lor y, \lnot x \land y\right\} \\
		&\left\{x \lor y, \lnot x, \lnot y\right\} \\
		&\left\{x, \lnot x, \lnot y\right\} \quad  \left\{y, \lnot x, \lnot y\right\}.
	\end{align*}

	Tous les sous-ensembles de littéraux sont non-satisfaisables, donc la formule $\phi$ est non-satisfaisable (i.e. $\lnot \phi$ est valide).
	\end{ex}

	L'algorithme de création de tableau sémantique pour SAT est le suivant. Soit $\phi$ une formule sur $P$. On construit l'arbre $T_\phi$ comme suit~:
	\begin{enumerate}
		\item Initialisation~: l'arbre est défini par $T_\phi = \{\phi\}$.
		\item Tant qu'il existe une feuille $\mathcal L \in T_\phi$ telle que $\exists \psi \in \mathcal L$, une formule simplifiable (donc contenant une
		conjonction ou une disjonction)~:
		\begin{itemize}
			\item si $\psi$ est simplifiable par une $\land$-règle, on ajoute une feuille $\mathcal L'$ à $\mathcal L$ telle que~:
			\[\mathcal L' = \left(\mathcal L \setminus \{\psi\}\right) \cup \{\psi_1, \psi_2\},\]
			pour $\psi_1$ et $\psi_2$, les deux sous-formules simplifiées de $\psi$~;
			\item si $\psi$ est simplifiable par une $\lor$-règle, on ajoute deux feuilles $\mathcal L_1$ et $\mathcal L_2$ à $\mathcal L$
			telles que~:
			\[\forall i \in \intint 12 : \mathcal L_i = \left(\mathcal L \setminus \{\psi\}\right) \cup \{\psi_i\},\]
			avec $\psi_1$ et $\psi_2$, les deux sous-formules simplifiées de $\psi$.i
		\end{itemize}
		\item S'il existe $\mathcal L \in T_\phi$, une feuille telle que $\mathcal L$ est satisfaisable, alors retourner \texttt{SATISFAISABLE}, sinon retourner
		\texttt{NON-SATISFAISABLE}.
	\end{enumerate}

\section{Déduction naturelle}
	\begin{déf} Soient $n \in \N^*$, $\{\phi_i\}_{i \in \intint 1n}$, $\psi$ des formules sur $P$. Si $\psi$ peut être dérivé des $\{\phi_i\}_{i \in \intint 1n}$,
	on appelle ces derniers des \textit{prémisses} et $\psi$ la \textit{conclusion}. On note cela~:
	\[\phi_1, \ldots, \phi_n \vdash \psi.\]

	On appelle cela un \textit{séquent}.
	\end{déf}

	La déduction naturelle fonctionne par élimination et introduction successives d'opérateurs.

	\begin{itemize}
		\item $\frac {\phi \quad \psi}{\phi \land \psi}\land_i$ se lit \textit{si $\phi$ et si $\psi$, alors $\phi$ et $\psi$}~;
		\item $\frac {\phi \land \psi}{\psi}\land_{e_1}$ se lit \textit{si $\phi$ et $\psi$, alors en particulier $\psi$}.
	\end{itemize}

	De même pour $\land_{e_2}$, et $\lor_i$. La double négation fonctionne également par introduction et élimination.

	La règle d'élimination de l'implication s'appelle \textit{Modus Ponens} (MP) et la règle d'élimination de l'implication par contraposée s'appelle
	\textit{Modus Tollens} (MT)~:
	\begin{itemize}
		\item $\frac {\phi \quad \phi \Rightarrow \psi}{\psi}MP$ se lit \textit{si $\phi$ et si $\phi$ implique $\psi$, alors $\psi$}~;
		\item $\frac {\lnot \psi \quad \phi \Rightarrow \psi}{\lnot \phi}MT$ se lit \textit{si $\phi$ implique $\psi$ et non-$\psi$, alors non-$\phi$}.
	\end{itemize}

	Afin d'introduire l'implication, on se sert du MT~:

	\begin{tabular}{l l l}
	1. & $x \Rightarrow y$ & prémisse \\
	2. & $\lnot y$ & hyp. \\
	3. & $\lnot x$ & MT 1, 2~; fin hyp. 2 \\
	4. & $\lnot \Rightarrow \lnot y$ & $\Rightarrow_i$ 2, 3
	\end{tabular}
	\qquad On déduit donc $\lnot y \Rightarrow \lnot x$.

	De manière plus générale, si en faisant l'hypothèse $\phi$, on arrive à la conclusion $\psi$, pour $\phi, \psi$ deux formules sur $P$, alors~:
	\[\frac {\begin{tabular}{l l}$\phi$ & \text{hyp.}\\\vdots & \\$\psi$ & \text{fin hyp.}\end{tabular}}{\phi \Rightarrow \psi}\Rightarrow_i\]

	\begin{rmq} Les prémisses et les hypothèses sont fondamentalement différentes~! Une hypothèse peut être émise même sans hypothèse, e.g.~:

	\begin{tabular}{l l l}
	1. & $p$ & hyp. \\
	2. & $\lnot\lnot p$ & $\lnot\lnot_i$ 1~; fin hyp. 1 \\
	3. & $p \Rightarrow \lnot\lnot p$ & $\Rightarrow_i$ 1, 2
	\end{tabular}

	On peut donc déduire de cela que $\vdash p \Rightarrow \lnot\lnot p$.
	\end{rmq}

	Afin d'éliminer la disjonction, on procède de la sorte~:

	\[\frac {
		\begin{tabular}{l l l l l}
			& $\phi_1$ & hyp. & $\phi_2$ & hyp. \\
			& \vdots   &       &  \vdots  & \\
			$\phi_1 \lor \phi_2$ & $\psi$ & fin hyp. & $\psi$ & fin hyp.
		\end{tabular}
	}{\psi}\lor_e\]

	\begin{déf} Toute formule $\phi$ sur $P$ telle que $\vdash \phi$ est appelée \textit{théorème}.
	\end{déf}

	Un théorème n'a donc pas besoin de prémisse. De plus, $\vdash \phi$ si et seulement si $\models \phi$, donc les théorèmes coïncident avec les formules valides.

	\begin{lem} Soient $n \in \N^*$, $\{\phi_i\}_{i \in \intint 1n}$, $\psi$ des formules sur $P$. Alors~:
	\[\phi_1, \ldots, \phi_n \vdash \psi \qquad \text{ si et seulement si }
		\qquad \vdash \phi_1 \Rightarrow \phi_2 \Rightarrow \ldots \Rightarrow \phi_n \Rightarrow \psi.\]
	\end{lem}

	Afin d'introduire la négation, on suppose une formule, et on en dérive $\bot$, ce qui permet d'en déduire sa négation. Cela se formule~:
	\[\frac {\begin{tabular}{l l}$\phi$ & hyp. \\ \vdots &\\$\bot$ & fin hyp.\end{tabular}}{\lnot\phi}\lnot_i\]

	Un raisonnement par l'absurde (reductio ad absurdum) se formalise par une introduction de double négation~:

	\[\frac {\begin{tabular}{l l}$\lnot \phi$ & hyp. \\ \vdots &\\ $\bot$ & fin hyp.\end{tabular}}{\lnot\lnot \phi}RAA,\]
	qui se note~:
	\[\frac {\phi}{\lnot\lnot\phi}\lnot\lnot_i.\]

	Ce qui est également équivalent à la loi du tiers exclus, que l'on peut formuler $\phi \Rightarrow \lnot(\lnot\phi)$, ou encore~:
	\[\frac {}{\phi \lor \lnot \phi}LEM.\]

	\begin{thm}Soient $n \in \N^*$, $\{\phi_i\}_{i \in \intint 1n}$, $\psi$ des formules sur $P$. Alors~:
	\begin{itemize}
		\item[(Adéquation)] $\left(\phi_1, \ldots, \phi_n \vdash  \psi\right) \Rightarrow \left(\phi_1, \ldots, \phi_n \models \psi\right)~;$
		\item[(Complétude)] $\left(\phi_1, \ldots, \phi_n \models \psi\right) \Rightarrow \left(\phi_1, \ldots, \phi_n \vdash  \psi\right).$
	\end{itemize}
	\end{thm}

	\begin{déf} Une formule $\phi$ sur $P$ est dit en \textit{forme normale conjonctive} (FNC ou CNF) lorsqu'elle s'exprime comme suit~:
	\[\phi \equiv \bigwedge_{i=1}^n\left(\bigvee_{j=1}^m\ell_{ij}\right),\]
	et est dite en \textit{forme normale disjonctive} (FND ou DNF) lorsqu'elle s'exprime comme suit~:
	\[\phi \equiv \bigvee_{i=1}^n\left(\bigwedge_{j=1}^m\ell_{ij}\right),\]
	avec $\ell_{ij}$ des littéraux sur $P$.
	\end{déf}

	\begin{prp} Deux formules $\phi$ et $\psi$ sur $P$ sont équivalentes si et seulement si $\logeval \phi_\cdot \equiv \logeval \psi$ sur $\{0, 1\}^P$.
	\end{prp}

	\begin{thm} Soit $\phi$ une formule sur $P$. Il existe $\phi_C$ et $\phi_D$  respectivement sous forme conjonctive et disjonctive telles que~:
	\[\phi \equiv \phi_C \equiv \phi_D.\]
	\end{thm}

\section{Coupures}
	\begin{déf} Une formule $\phi$ sur $P$ est une \textit{clause} si $\phi = \bot$, ou si il existe $\ell_1, \ldots, \ell_n$ littéraux
	tels que $\phi = \bigvee_{i=1}^n\ell_i$.
	\end{déf}

	\begin{déf} Une clause $C$ est dite \textit{positive} si tous les littéraux apparaissent positivement, et est dite \textit{négative} si tous les
	littéraux apparaissent négativement. Elle est dite \textit{tautologique} si elle contient deux littéraux complémentaires, i.e. si $\phi \equiv \top$.
	\end{déf}

	\begin{rmq} Une clause $C$ est non-satisfaisable si et seulement si $C = \bot$.
	\end{rmq}

	\begin{déf}~
	\begin{itemize}
		\item Un ensemble de clauses $S$ est dit \textit{satisfaisable par une valuation $V \in \{0, 1\}^P$}, noté $V \models S$ lorsque~:
		\[\forall C \in S : V \models C~;\]
		\item un ensemble $S$ de clauses est dit \textit{satisfaisable} s'il existe $V \in \{0, 1\}^* \tq V \models S$~;
		\item un ensemble $S$ de clauses est dit \textit{valide} si $\forall V \in \{0, 1\}^P : V \models S$~;
		\item une clause $C$ est dite \textit{conséquence d'un ensemble de clauses $S$} lorsque~:
		\[\forall V \in \{0, 1\}^P : \left(V \models S \Rightarrow V \models C\right),\]
		que l'on note $S \models C$.
	\end{itemize}
	\end{déf}

	\begin{prp} Soient $S$ un ensemble de clauses, et $C$ une clause tautologique. $S$ est satisfaisable (resp. valide) si et seulement si $S \cup \{C\}$
	est satisfaisable (resp. valide).
	\end{prp}

	\begin{prp} Toute formule $\phi$ sur $P$ est équivalente à un nombre fini de clauses.
	\end{prp}

	\begin{proof} Il existe $\phi_C$ telle que $\phi \equiv \phi_D$. Or $\phi_C$ est une conjonction de clauses.
	\end{proof}

	\begin{déf} Soient $C_1, C_2$ deux clauses telles qu'il existe $p$, un littéral tel que~:
	\[C_1 = \bigvee_{i=1}^{n_1}\ell_{1i} \lor p \qquad \text{ et } \qquad C_2 = \bigvee_{i=1}^{n_2} \ell_{2i} \lor (\lnot p).\]

	La règle de coupure dit que la clause $C_3 = \bigvee_{i=1}^2\bigvee_{j=1}^{n_i}\ell_{ij}$ est conséquence de $C_1$ et $C_2$, que l'on note $C_1,C_2 \vdash_p^c C_3$.
	\end{déf}

	\begin{thm} Soient $C_1, C_2, C_3$, trois clauses telles qu'il existe $p$ tel que $C_1,C_2 \vdash_p^c C_3$. $C_3$ est conséquence logique de $C_1$ et $C_2$, i.e.~:
	\[C_1 \land C_2 \models C_3.\]
	\end{thm}

	\begin{proof} Soit $V \in \{0, 1\}^P$ telle que $V \models C_1 \land C_2$. Si $V(p) = 0$, alors $V \models C_2$. Or $V \models C_1 \land C_2$, donc il existe
	$i \in \intint 1{n_1}$ tel que $V(\ell_{1i}) = 1$. Donc $V \models C_3$.

	Idem si $V(p) = 1$, on sait que $V \models C_1$, mais puisque $V \models C_1 \land C_2$, il doit exister $i \in \intint 1{n_2}$ tel que $V(\ell_{2i}) = 1$,
	et donc $V \models C_3$.
	\end{proof}

	\begin{déf} Soit $C = \bigvee_{i=1}^n\ell_i$, une clause, pour $\{\ell_i\}_{i \in \intint 1n}$ des littéraux. S'il existe $j, j'$ tels que
	$j \neq j'$ et $\ell_j \equiv \ell_{j'}$, alors la règle de retrait de redondance dit~:
	\[C \vdash_r \bigvee_{\stackrel {i \in \intint 1n}{i \neq j}}\ell_i.\]
	\end{déf}

	\begin{déf} Soient $S$, un ensemble de clauses, et $C$ une clause. Une preuve de $C$ par coupures de $S$ est une suite finie de clauses $\{C_i\}_{i \in \intint 1n}$
	où $C_n = C$, et $\forall i \in \intint 1n$~:
	\begin{itemize}
		\item soit $C_i \in S$~;
		\item soit $\exists (k, \ell) \in \intint 1n^2 \tq k < \ell < i$ et $C_k,C_\ell \vdash^c C_i$~;
		\item soit $\exists k \in \intint 1{i-1} \tq C_k \vdash_r C_i$.
	\end{itemize}

	On note $S \vdash^c C$ le fait que $C$ soit déductible par coupure de $S$.
	\end{déf}

	\begin{thm} Soient $S$ un ensemble de clauses et $C$ une clause. Si $S \vdash^c C$, alors $S \models C$.
	\end{thm}

	\begin{déf} Une réfutation d'un ensemble de clauses $S$ par coupure est une dérivation de la clause vide à partir de $S$.
	\end{déf}

	\begin{thm} S'il existe une réfutation de $S$, un ensemble de clauses, par coupure, alors $S$ est non-satisfaisable.
	\end{thm}

	Afin de prouver $\psi_1, \ldots, \psi_n \models \phi$ pour $\{\psi_i\}_{i \in \intint 1n}$ et $\phi$ des formules sur $R$, on construit $S$
	l'ensemble de clauses équivalent à $\bigwedge_{i=1}^n\psi_i$, et $S'$ l'ensemble de clauses équivalent à $\lnot \phi$. Pour $D$ l'ensemble
	des clauses dérivables depuis $S \cup S'$, si $\bot \in D$, alors $\bigwedge_{i=1}^n\psi_i \land \lnot \phi$ est non-satisfaisable, et donc~:
	\[\psi_1, \ldots, \psi_n \models \phi.\]

	\begin{thm} Si un ensemble de clauses $S$ est non-satisfaisable, alors il existe une réfutation finie de $S$ par coupure.
	\end{thm}

	Un SAT-solver est un programme qui décide le problème SAT. Si son entrée $S$ est satisfaisable, il retourne une valuation qui la satisfait.

	Le problème SAT est $\NP$-complet, donc il est pensé qu'il n'existe pas d'algorithme de résolution en temps polynomial.

\section{DPLL}
	DPLL est un algorithme de résolution du problème SAT.

	\begin{déf} Une valuation partielle est une assignation arbitraire d'un littéral $x$ à 0 ou 1, noté $x/1$ ou $x/0$.
	\end{déf}

	Pour $C$ une clause, $x$ un littéral de $C$ et $b \in \{0, 1\}$, une valuation partielle de la clause $C$, notée $C[x/b]$ est obtenue par~:
	\begin{itemize}
		\item si $C$ ne contient ni $x$ ni $\lnot x$, alors $C[x/b] = C$~;
		\item si $C \in \{x, \lnot x\}$, alors $C[x/b] =
			\begin{cases}\top &\text{ si } \left(C = x \text{ et } b = 1\right) \text{ ou } \left(C =\lnot x \text{ et } b = 0\right) \\ \bot &\text{ sinon}\end{cases}$~;
		\item si $C$ contient $x$ et $b=1$ ou si $C$ contient $\lnot x$ et $b=0$, alors $C = \top$~;
		\item sinon on retire les occurrences de $x$ ou $\lnot x$ de $C$.
	\end{itemize}

	Donc pour $\phi = \bigwedge_{i=1}^nC_i$, on définit~:
	\[\phi[x/b] = \bigwedge_{i=1}^nC_i[x/b] = \bigwedge_{\stackrel {i \in \intint 1n}{C_i[x/b] \neq \top}}C_i[x/b].\]

	On remarque donc que s'il existe $i \in \intint 1n$ tel que $C_i[x/b] = \bot$, alors $\phi[x/b] = \bot$, et si $\forall i \in \intint 1n : C_i[x/b] = \top$,
	alors $\phi[x/b]=\top$.

	De plus, $\phi[x/b]$ est une formule sur $P \setminus \{x\}$, donc on peut lui réappliquer une valuation partielle $y/b'$.

	L'algorithme DPLL fonctionne par valuation partielles sur un littéral (appelé \textit{pivot}) et teste récursivement jusqu'à déterminer une valuation
	qui satisfait la clause.

	\begin{déf} Une clause $C$ est dite \textit{unitaire} si $C = x$ ou $C = \lnot x$.
	\end{déf}

	\begin{rmq} Une clause unitaire force le choix du pivot, et de sa valuation. De plus, après valuation partielle, une clause peut devenir une clause unitaire.
	Les SAT-solvers font donc de la \textit{propagation de clauses unitaires}.
	\end{rmq}

	Également, si un littéral apparait toujours positivement (ou négativement) dans les clauses, alors il est possible de les éliminer du problème par valuation
	partielle à 0 si négatif, et 1 si positif. Le procédé DPLL peut donc être exprimé comme suit~:
	\begin{enumerate}
		\item Si $\phi = \top$, retourner 1 et si $\phi = \bot$, retourner 0.
		\item Si $\phi$ contient une clause unitaire $C_1$, retourner
			$\begin{cases}DPLL(\phi[x/1]) &\text{ si } C_1 = x \\DPLL(\phi[x/0]) &\text{ si } C_1 = \lnot x\end{cases}$.
		\item Si $\phi$ contient un littéral $x$ de polarité constante $\pi$, alors retourner
			$\begin{cases}DPLL(\phi[x/1]) &\text{ si } \pi=+\\DPLL(\phi[x/0]) &\text{ si } \pi=-\end{cases}$.
			\item Sinon, choisir un littéral $x$ au hasard, et renvoyer $DPLL(\phi[x/0]) \lor DPLL(\phi[x/1])$.
	\end{enumerate}

	\subsection{Transformation de Tseitin}
		Lorsqu'une formule n'est pas simple à mettre sous FNC (e.g. si elle est sous FND), on peut lui appliquer la transformation de Tseitin.
		Soit $\phi \equiv \bigwedge_{i=1}^nC_i$, une formule sous FND, avec les $C_i$, des conjonctions de littéraux. Sa transformation de Tseitin
		donne~:
		\[\psi \coloneqq \mathscr T(\phi) \equiv \left(\bigvee_{i=1}^nx_i\right) \land \left(\bigwedge_{i=1}^n\left(x_i \Leftrightarrow C_i\right)\right).\]

		le but est donc d'ajouter de nouvelles variables $x_i$, en les forçant à être équivalentes aux clauses $C_i$.

		Une fois la transformation appliquée, il est facile de la mettre sous FNC. Pour $C_i \equiv \bigwedge_{j=1}^{n_i}\ell_{ij}$~:
		\begin{align*}
			x_i \Leftrightarrow C_i &\equiv (x_i \Rightarrow C_i) \land (C_i \Rightarrow x_i) \\
			&\equiv \left(\lnot x_i \lor \bigwedge_{j=1}^{n_i}\ell_{ij}\right) \land \left(\bigvee_{j=1}^{n_i}\lnot \ell_{ij} \lor x_i\right) \\
			&\equiv \bigwedge_{j=1}^{n_i}(\lnot x_i \lor \ell_{ij}) \land \left(\bigvee_{j=1}^{n_i}\ell_{ij} \lor x_i\right).
		\end{align*}

	\subsection{Contrainte exactement une}
		Afin d'encoder la contrainte \textit{exactement une parmi $n$}, la solution naïve est~:
		\[\left(\bigvee_{i=1}^nx_i\right) \land \bigwedge_{i=1}^n\bigwedge_{j=i+1}^n(\lnot x_i \lor \lnot x_j).\]
		Cela fait $1+n(n-1)/2$ contraintes. Si $n=2^k$, une solution plus intéressante est d'introduire les variables $\{b_i\}_{i \in \intint 1k}$, et d'introduire
		la notation $\overline {\alpha_1\ldots\alpha_k} = \overline {i-1}$ pour la représentation binaire de $i-1$. On peut alors exprimer~:
		\[\left(\bigvee_{i=1}^nx_i\right) \land \bigwedge_{i=1}^n(x_i \Rightarrow B_i),\]
		avec $B_i$ défini pour $i \in \intint 1n$ comme étant~:
		\[B_i = \bigwedge_{j=1}^k\ell_{ij},\]
		pour $\ell_{ij} = \begin{cases}b_j &\text{ si }\alpha_j = 1 \\\lnot b_j&\text{ sinon}\end{cases}$. Puisque~:
		\[\bigwedge_{i=1}^n(x_i \Rightarrow B_i) \equiv \bigwedge_{i=1}^n\bigwedge_{j=1}^k(\lnot x_i \lor \ell_{ij}),\]
		cela fait descendre le nombre de contraintes à $1+nk = 1+n\log_2(n)$. L'idée est d'utiliser l'unicité de la représentation binaire d'un nombre pour garantir
		qu'une seule des variables est assignée positivement.

		Dès lors, si $V : \{0, 1\}^{\{x_i\}_{i \in \intint 1n} \cup \{b_i\}_{i \in \intint 1k}} \to \{0, 1\}$ est une solution, alors $\abs {V^{-1}(\{1\})} = 1$.

		Un principe souvent valable pour les SAT-solvers est qu'il est préférable d'ajouter des variables afin de minimiser le nombre de clauses.

\section{Complexité}
	\begin{déf} Un alphabet $\Sigma$ est un ensemble fini de symboles. On note $\Sigma^*$ l'ensemble des mots sur $\Sigma$, i.e.~:
	\[\Sigma^* = \lim_{n \to +\infty}\bigsqcup_{\ell=1}^n\Sigma^\ell.\]
	\end{déf}

	\begin{déf} Tout alphabet permet de former un mot commun appelé le \textit{mot vide}, noté $\epsilon$.
	\end{déf}

	\begin{déf} Un langage sur un alphabet est un sous-ensemble $L \subseteq \Sigma^*$.
	\end{déf}

	Un problème de décision est un langage $P$ sur un alphabet $\Sigma$. On peut alors définir~:
	\[\chi_P : \Sigma^* \to \{0, 1\} : m \mapsto \begin{cases}1 &\text{ si } m \in P \\0 &\text{ sinon}.\end{cases}\]

	La représentation abstraite du codage sert en théorie de la complexité et de la calculabilité, mais bien souvent, il n'est pas nécessaire de s'y restreindre.
	Notons que l'encodage peut influencer la complexité.

	\begin{déf} Un problème de décision $P \subset \Sigma^*$ est dit \textit{décidé par un algorithme $A$} si pour tout $m \in \Sigma^*$,
	$A(m)$ termine et retourne 1 si $m \in P$ et 0 si $m \in \Sigma^* \setminus P$. Si un tel algorithme existe, $A$ est dit décidable.
	\end{déf}

	\begin{déf} La classe $\mathcal P$ définit les problèmes décidables en temps polynomial, i.e. $P \subset \Sigma^*$ est dans $\mathcal P$ s'il existe
	$k \in \N^*$ et $A$, un algorithme tels que $\forall m \in \Sigma^n \subset \Sigma^* : A$ retourne 1 (resp. 0) en temps $O(n^k)$ si
	$m \in P$ (resp. si $m \in \Sigma^* \setminus P$).
	\end{déf}

	\begin{déf} Un algorithme de vérification pour un problème $P \subseteq \Sigma^*$ est un algorithme~:
	\[A : \Sigma^* \times \Sigma^* \to \{0, 1\} \tq P = \left\{u \in \Sigma^* \tq \exists v \in \Sigma^* \tq A(u, v) = 1\right\}.\]

	Pour $u \in \Sigma^*$, tout $v \in \Sigma^*$ tel que $A(u, v) = 1$ est appelé \textit{certificat pour $u$}.
	\end{déf}

	\begin{déf} La classe $\NP$ définit les problèmes vérifiables en temps polynomial et la classe $\ExpTime$ définit les programmes qui sont décidables
	en temps exponentiel.
	\end{déf}

	\begin{thm} $\mathcal P \subset \NP \subset \ExpTime$.
	\end{thm}

	\begin{déf} un problème $P \in \NP$ est dit \textit{$\NP$-complet} si tout problème $Q \in \NP$ peut être réduit à $P$ en temps polynomial.

	Un problème $P$ est dit $\NP$-dur si tout problème $\NP$-complet $Q$ peut être réduit à $P$ en temps polynomial.
	\end{déf}

	\begin{rmq} Les problèmes $\NP$-complets sont donc $\NP$-durs, mais tout les problèmes $\NP$-durs ne sont pas forcément $\NP$.
	\end{rmq}

	\begin{thm}[Théorème de Cooke] Le problème SAT est $\NP$-complet.
	\end{thm}

	\begin{prp} Soient $P, Q \in \NP$. Si $P$ est $\NP$-complet et $P$ se réduit à $Q$ en temps polynomial, alors $Q$ est $\NP$-complet.
	\end{prp}

	\begin{proof} La composition de deux algorithmes polynomiaux en temps est polynomiale en temps. Un problème $P' \in \NP$ peut être
	réduit en $P$ par un algorithme $R_{P'P}$ polynomial en temps par hypothèse, et il existe un algorithme $R_{PQ}$ polynomial en temps
	qui réduit $P$ en $Q$. La composition $R_{PQ} \circ R_{P'P}$ réduit donc $P'$ en $Q$ en temps polynomial.
	\end{proof}

\section{Logique du premier ordre}
	En logique propositionnelle, les valeurs sont définies dans $\{0, 1\}$. En logique des prédicats, on généralise à des ensembles quelconques et on définit
	des \textit{prédicats} (relations) sur les variables.

	\begin{déf} Un langage du premier ordre est un langage défini sur un vocabulaire (symboles de fonctions, de prédicats, de relations, etc.)
	\end{déf}

	L'alphabet d'un langage du premier ordre contient les éléments communs à tous langages (connecteurs, parenthèses, etc.), et un ensemble $\mathcal V$
	\textbf{infini} de symboles de variables et muni de symboles de symboles de relations ($p, q, r, \ldots$), de fonctions ($f, g, h, \ldots$), et de
	constantes ($a, b, c, \ldots$).

	\begin{déf} Soit un prédicat ou une fonction $P$. On appelle \textit{arité} $n \in \N^*$ de $P$ le nombre de paramètres de $P$. On note son arité $P|_n$.
	\end{déf}

	\begin{déf} Si $=$ fait partie du vocabulaire du langage du premier ordre, il est dit \textit{égalitaire}.
	\end{déf}

	\begin{déf} L'ensemble $\mathcal T$ des termes d'un langage du premier ordre $\mathcal L$ est le plus petit ensemble (au sens de l'inclusion) tel que~:
	\begin{itemize}
		\item tous les symboles de variables ou constantes de $\mathcal L$ sont dans $\mathcal T$~;
		\item si $f$ est un symbole de fonction d'arité $n$, alors $\forall (t_1, \ldots, t_n) \in \mathcal T^n : f(t_1, \ldots, t_n) \in \mathcal T$.
	\end{itemize}
	\end{déf}

	\begin{rmq} Notons que les prédicats ne fournissent pas de termes.
	\end{rmq}

	\begin{déf} l'ensemble des formules atomiques $\mathcal A$ d'un langage du premier ordre $\mathcal L$ est l'ensemble des formules sur $\mathcal L$ telles que~:
	\begin{itemize}
		\item pour tout prédicat $p$ d'arité $n$ du vocabulaire de $\mathcal L$~:
		\[\forall (t_1, \ldots, t_n) \in \mathcal T^n : p(t_1, \ldots, t_n) \in \mathcal A~;\]
		\item si $\mathcal L$ est égalitaire, alors $\forall (t_1, t_2) \in \mathcal T^2 : (t_1=t_2) \in \mathcal A$.
	\end{itemize}
	\end{déf}

	\begin{déf} Soit $\mathcal L$ un langage du premier ordre. On définit $\mathcal F(\mathcal L)$, l'ensemble des formules $\phi$ bien formées
	obtenues sur $\mathcal L$, i.e. suivant la grammaire~:
	\[\phi ::= p(t_1, \ldots, t_n) \mid \exists x \tq \psi \mid \forall x : \psi \mid \phi_p,\]
	pour $p$ une relation, $t_1, \ldots, t_n$ des termes, $\psi \in \mathcal F(\mathcal L)$ et $\phi_p$, une formule de langage propositionnel.
	\end{déf}

	\begin{rmq} Les quantificateurs $\exists$ et $\forall$ ont la même précédence que $\lnot$.
	\end{rmq}

	\begin{déf} Une formule $\phi$ est une sous-formule de $\psi$ lorsque $\phi$ apparait dans une décomposition de $\psi$.
	\end{déf}

	\begin{déf} Une occurrence d'une variable dans un formule est un couple constitué de la variable et d'une place effective (i.e. ne suivant pas directement
	un quantificateur).
	\end{déf}

	\begin{déf} Une occurrence d'une variable $x$ dans une formule $\phi$ est dite \textit{libre} si elle n'apparait dans aucune sous-formule commençant par
	un quantificateur. Elle est dite \textit{liée} sinon.
	\end{déf}

	\begin{déf} Si une variable admet une occurrence libre dans une formule $\phi$, elle est dite libre dans $\phi$.
	\end{déf}

	\begin{déf} Une formule $\phi$ sans variable libre est dite \textit{close}.
	\end{déf}

	\begin{rmq} Une formule $\phi$ non-close est souvent notée $\phi(x_1, \ldots, x_n)$ pour $x_1, \ldots, x_n$ ses variables libres.
	\end{rmq}

	\begin{déf} Une structure $\mathcal M$ sur un langage $\mathcal L$ est un tuple contenant~:
	\begin{itemize}
		\item $M$, un ensemble non-vide appelé \textit{domaine}~;
		\item une interprétation des symboles des prédicats par des relations sur $M$~;
		\item une interprétation des symboles des fonctions par des fonctions de $M^n$ dans $M$~;
		\item une interprétation des symboles de constantes par des éléments de $M$.
	\end{itemize}

	Pour tout prédicat $r|_n$, on note son interprétation $r^{\mathcal M} \subset M^n$. Pour toute fonction $f|_n$, on note $f^{\mathcal M} : M^n \to M$
	son interprétation. Pour toute constante $c$, on note $c^{\mathcal M} \in M$ son interprétation.
	\end{déf}

	\begin{déf} Pour $\mathcal V$, un ensemble de variables et $M$, un domaine, on définit une valuation comme étant une fonction $V \in M^{\mathcal V}$.

	Soit $\mathcal M$, une structure, et $\mathcal V$ un ensemble de variables. Pour $t \in \mathcal T$, on définit sa valuation par~:
	\[t^{\mathcal M,V} = \begin{cases}
		c^{\mathcal M} &\text{ si $t$ est une constante $c$} \\
		V(x) &\text{ si } t=x \in \mathcal V\\
		f^{\mathcal M}(t_1^{\mathcal M,V}, \ldots, t_n^{\mathcal M,V}) &\text{ si } t = f(t_1, \ldots, t_n).
		\end{cases}\]
	\end{déf}

	\begin{déf} Une formule $\phi$ sur $\mathcal L$ est dite \textit{satisfaite} dans $\mathcal M$ par $V \in M^{\mathcal V}$ lorsque~:
	\begin{itemize}
		\item si $\mathcal L$ est égalitaire et $\phi \equiv t_1 = t_2$ et $t_1^{\mathcal M,V}=t_2^{\mathcal M,V}$~;
		\item ou si $\phi \equiv r(t_1, \ldots, t_n)$ et $(t_i^{\mathcal M,V})_{i \in \intint 1n} \in r^{\mathcal M}$.
	\end{itemize}
	On note cela $\mathcal M,V \models \phi$.
	\end{déf}

	\begin{déf} On appelle \textit{valeur} d'une formule $\phi$ sur $\mathcal L$ dans $\mathcal M$ l'ensemble~:
	\[\mathcal W \coloneqq \left\{V \in M^{\mathcal V} \tq \mathcal M,V \models \phi\right\}.\]
	\end{déf}

	Si $\phi$ est close, alors sa valeur de vérité dans $(\mathcal M, V)$ ne dépend pas de $V$. Dans le cas où une telle formule est vraie dans
	une structure $\mathcal M$, on note $\mathcal M \models \phi$, et on dit que $\mathcal M$ est un \textit{modèle} pour $\phi$.

	\begin{déf} Soit $\phi$ une formule ayant $x_1, \ldots, x_n$ pour variables libres. On définit sa \textit{cloture universelle} par~:
	\[\overline \phi \equiv \forall x_1 : \forall x_2 : \ldots \forall x_n : \phi(x_1, \ldots, ,x_n).\]
	\end{déf}

	\begin{déf} Soient $\mathcal L$, un langage du premier ordre, $\mathcal M$, une structure sur $\mathcal L$, et $\phi$, une formule sur $\mathcal L$.
	On dit que $\mathcal M$ satisfait $\phi$ lorsque $\mathcal M \models \overline \phi$.

	Deux formules $\phi$ et $\psi$ sont \textit{équivalentes} si~:
	\[\forall \mathcal M : \forall V \in M^{\mathcal V} : \mathcal M,V \models \phi \Leftrightarrow \mathcal M,V \models \psi.\]
	\end{déf}

\section{Indécidabilité}
	\begin{déf} Un problème de décision $P \subseteq \Sigma^*$ est \textit{indécidable} lorsqu'il n'existe aucun algorithme $A : \Sigma^* \to \{0, 1\}$
	tel que pour tout $x \in \Sigma^*$ : $A$ retourne 1 si et seulement si $x \in P$ en un nombre fini d'étapes.
	\end{déf}

	\begin{thm} le problème de l'arrêt est indécidable.
	\end{thm}

	\begin{proof} Par l'absurde, supposons qu'il existe un programme \texttt{HALT(C, x)} qui détermine par \texttt{C}, le code d'un programme si l'entrée
	\texttt{X} fera s'arrêter ledit programme. On définit le programme \texttt{PARADOX(C)} par~:
	\begin{itemize}
		\item si \texttt{HALT(C, C)} retourne 1, alors ne jamais s'arrêter~;
		\item sinon, retourner 0.
	\end{itemize}

	On en déduit que si \texttt{C'} est le code du programme \texttt{PARADOX}, alors l'appel \texttt{PARADOC(C')} s'arrêtera si et seulement si il
	ne s'arrête pas, ce qui est impossible. Il n'existe donc pas de tel programme \texttt{HALT}.
	\end{proof}

	\begin{prp} Soient $P_1, P_2$ deux problèmes tels que $P_1$ est indécidable. S'il existe une réduction de $P_1$ vers $P_2$, alors $P_2$ est indécidable.
	\end{prp}

	\begin{proof} Soit $R_{12}$, une réduction du problème $P_1$ en $P_2$. $R_{12}$ associe à toute entrée $I_1$ du problème $P_1$ une entrée $I_2$ du
	problème $P_2$ telle que $I_1$ mène à une solution pour le problème $P_1$ si et seulement si $I_2$ mène à une solution pour le problème $P_2$.

	Supposons par l'absurde qu'il existe un algorithme $A$ qui décide $P_2$. Dès lors, à l'aide de la réduction, le problème $P_1$ est décidable, ce qui
	est une contradiction. Donc il n'existe pas de tel algorithme $A$, et $P_2$ est indécidable.
	\end{proof}

	\subsection{Problème de Correspondance de Post (PCP)}
		Soit $\Sigma = \{0, 1\}$, un alphabet, et soient $u, v \in \Sigma^*$. On définit la \textit{concaténation} $uv$ par~:
		\[uv = (u_1, \ldots, u_{n_1}, v_1, \ldots, v_{n_2})\qquad\text{ pour } (u, v) \in \Sigma^{n_1} \times \Sigma^{n_2}, n_1, n_2 \in \N.\]

		Le PCP est défini par~:
		\begin{itemize}
			\item[ENTRÉE~:] $n \in \N$ couples de mots sur $\Sigma$, $\{(u_i, v_i)\}_{i \in \intint 1n}$.
			\item[SORTIE~:] 1 s'il existe $k \in \N^*$ et $(i_1, \ldots, i_k) \in \intint 1n^k$ tels que $u_{i_1}u_{i_2}\ldots u_{i_k} = v_{i_1}v_{i_2}\ldots v_{i_k}$.
		\end{itemize}

		\begin{thm} Soit $\Sigma$ un alphabet. Si $\abs \Sigma < 2$, alors $PCP(\Sigma)$ est décidable, et si $\abs \Sigma > 6$, alors $PCP(\Sigma)$ est indécidable.
		\end{thm}

		\begin{proof} Admis.
		\end{proof}

		\begin{rmq} La décidabilité de $PCP$ pour $\abs \Sigma \in \intint 26$ est un problème ouvert.
		\end{rmq}

		\begin{thm} Le problème de validité en logique du premier ordre est indécidable.
		\end{thm}

		\begin{proof} Montrons cela par réduction du PCP en validité en logique du premier ordre.

		Soit $\mathcal L = \{p, f_0, f_1, a\}$, un langage du premier ordre avec $p$, une relation, $f_0$ et $f_1$ des fonctions, et $a$ une constante.
		Soit $u \in \Sigma^*$ un mot, et soit $g \in \mathcal T$. On définit~:
		\[t_u(g) \coloneqq \begin{cases}g &\text{ si } u=\epsilon\\\left(\bigcirc_{i=1}^{\abs u}f_{u_{\abs u+1-i}}\right)(g) &\text{ sinon}\end{cases}.\]

		Soit $I = \{(u_i, v_i)\}_{i \in \intint 1n}$, une instance de $PCP(\{0, 1\})$. On définit les formules $\rho, \sigma, \tau$ comme suit~:
		\begin{align*}
			\rho &\equiv \bigwedge_{i=1}^np(t_{u_i}(a), t_{v_i}(a)), \\
			\sigma &\equiv \forall x \forall y : \left(p(x, y) \Rightarrow \bigwedge_{i=1}^np(t_{u_i}(x), t_{v_i}(y))\right), \\
			\tau &\equiv \exists z \tq p(z, z).
		\end{align*}

		On définit alors la formule $\phi_I \coloneqq (\rho \land \sigma) \Rightarrow \tau$.

		Supposons qu'il existe $\{i_j\}_{j \in \intint 1k}$ pour l'entrée $I$ pour PCP, et montrons que $\phi_I$ est valide. Soit $\mathcal M$, une structure sur
		$\mathcal L$. On suppose que $\mathcal M \models \rho \land \sigma$. On sait que~:
		\[u \coloneqq u_{i_1}u_{i_2}\ldots u_{i_k} = v_{i_1}v_{i_2}\ldots v_{i_k} \eqqcolon v,\]
		donc, pour $n \coloneqq \sum_{j=1}^ki_j$~:
		\[\left(f_{u_n} \circ f_{u_{n-1}} \circ \ldots \circ f_{u_1}\right)(a) \equiv \left(f_{v_n} \circ f_{v_{n-1}} \circ \ldots \circ f_{v_1}\right)(a).\]

		Notons $g$ cette valeur (qui est dans $\mathcal T$). Puisque $\mathcal M \models \rho \land \sigma$, on a en particulier $\mathcal M \models \rho$
		et $\mathcal M \models \sigma$. Par $\rho$, on a $\forall j \in \intint 1k : t_{u_{i_j}}(a) = t_{v_{i_j}}(a)$. Par induction, et par $\sigma$, on a~:
		\[p\left(t_{u_{i_k}}( \ldots(t_{u_{i_1}}(a))), t_{v_{i_k}}(\ldots(t_{v_{i_1}}(a)))\right) = 1,\]
		i.e. $p(g, g)$. On en déduit $\mathcal M \models \tau$ sous l'hypothèse $\mathcal M \models \rho \land \sigma$, donc on déduit $\mathcal M \models \phi_I$.

		Supposons maintenant $\phi_I$ valide et montrons que $I$ admet une solution. Soit la structure $\mathcal H = (D,~f^{\mathcal H}~=~f,~p^{\mathcal H})$
		telle que $p^{\mathcal H}(a, a)=1$ et
		$\forall g, h \in \mathcal T : \forall (i, j) \in \intint 1k^2 : p^{\mathcal H}(t_{u_i}(g), t_{v_j}(h)) = \delta_i^jp^{\mathcal H}(g, h)$.

		Par définition de $p^{\mathcal H}$, il vient aisément que $\mathcal H \models \rho$ et $\mathcal H \models \sigma$. Par validité de $\phi_I$, il vient
		que $\mathcal H \models \tau$, i.e. $\mathcal H \models \exists z \tq p(z, z)$.

		Par définition des $t_{\cdot}(\cdot)$, il vient que $\exists k$ et que $z$ se décompose en~:
		\[z = t_{u_{i_k}}(\ldots(t_{u_1}(a))) = t_{v_{i_k}}(\ldots(t_{v_1}(a))).\]
		Dès lors, $u_{i_k}u_{i_{k-1}}\ldots u_{i_1} = v_{i_k}v_{i{k-1}}\ldots v_{i_1}.$
		\end{proof}
\end{document}
